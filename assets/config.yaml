graphdoc: 
  log_level: INFO                                       # The log level to use (DEBUG, INFO, WARNING, ERROR, CRITICAL)

mlflow: 
  mlflow_tracking_uri: !env MLFLOW_TRACKING_URI           # The tracking URI for MLflow
  mlflow_tracking_username: !env MLFLOW_TRACKING_USERNAME # The username for the mlflow tracking server
  mlflow_tracking_password: !env MLFLOW_TRACKING_PASSWORD # The password for the mlflow tracking server

language_model: 
  model: openai/gpt-4o                                  # Must be a valid dspy language model
  api_key: !env OPENAI_API_KEY                          # Must be a valid dspy language model API key
  cache: true                                           # Whether to cache the calls to the language model

data: 
  hf_api_key: !env HF_DATASET_KEY                       # Must be a valid Hugging Face API key (with permission to access graphdoc) # TODO: we may make this public in the future
  load_from_hf: false                                   # Whether to load the dataset from Hugging Face
  load_from_local: true                                 # Whether to load the dataset from a local directory
  load_local_specific_category: false                   # Whether to load all categories or a specific category (if load_from_local is true)
  local_specific_category: perfect                      # The specific category to load from the dataset (if load_from_local is true)
  local_parse_objects: false                            # Whether to parse the objects in the dataset (if load_from_local is true)
  split_for_eval: false                                 # Whether to split the dataset into trainset and evalset 
  trainset_size: 10                                     # The size of the trainset
  evalset_ratio: 0.1                                    # The proportionate size of the evalset
  data_helper_type: generation                          # Type of data helper to use (quality, generation)
  seed: 42                                              # The seed for the random number generator

prompt:
  prompt: base_doc_gen                                  # Which prompt signature to use
  class: DocGeneratorPrompt                             # Must be a child of SinglePrompt (we will use an enum to map this)
  type: chain_of_thought                                # The type of prompt to use (predict, chain_of_thought)
  metric: rating                                        # The type of metric to use (rating, category)
  load_from_mlflow: false                               # Whether to load the prompt from an MLFlow URI
  model_uri: null                                       # The tracking URI for MLflow
  model_name: null                                      # The name of the model in MLflow
  model_version: null                                   # The version of the model in MLflow
  prompt_metric: true                                   # Whether another prompt is used to calculate the metric (in which case we must also load that prompt)

prompt_metric:
  prompt: doc_quality                                   # The prompt to use to calculate the metric
  class: DocQualityPrompt                               # The class of the prompt to use to calculate the metric
  type: predict                                         # The type of prompt to use to calculate the metric
  metric: rating                                        # The metric to use to calculate the metric
  load_from_mlflow: false                               # Whether to load the prompt from an MLFlow URI
  model_uri: null                                       # The tracking URI for MLflow
  model_name: null                                      # The name of the model in MLflow
  model_version: null                                   # The version of the model in MLflow

trainer: 
  class: DocGeneratorTrainer                            # The type of trainer to use (DocQualityTrainer)
  optimizer_type: miprov2                               # The type of optimizer to use (miprov2, BootstrapFewShotWithRandomSearch)
  mlflow_model_name: doc_generator_model                # The name of the model in MLflow
  mlflow_experiment_name: doc_generator_experiment      # The name of the experiment in MLflow

optimizer: 
  optimizer_type: miprov2                               # BootstrapFewShotWithRandomSearch, miprov2
  auto: light                                           # miprov2 setting
  max_labeled_demos: 2                                  # max number of labeled demonstrations
  max_bootstrapped_demos: 4                             # max number of bootstrapped demonstrations
  num_trials: 2                                         # number of trials
  minibatch: true                                       # default true

module: 
  retry: true                                           # Whether to retry the generation if the quality check fails
  retry_limit: 1                                        # The maximum number of retries
  rating_threshold: 3                                   # The rating threshold for the quality check
  fill_empty_descriptions: true                         # Whether to fill the empty descriptions in the schema

eval:
  mlflow_experiment_name: doc_generator_eval            # The name of the experiment in MLflow
  generator_prediction_field: documented_schema         # The field in the generator prediction to use
  evaluator_prediction_field: rating                    # The field in the evaluator prediction to use
  readable_value: 25                                    # The value to make the ratings readable
